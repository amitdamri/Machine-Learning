{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qaMSASFqBwep",
        "KIqkVNC8B2Dg",
        "zZJIW2aMB5lf"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGLCv9rpEQ6x"
      },
      "source": [
        "# Imports + Downloading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OFX_GSwp8Gs",
        "outputId": "7933e916-5893-4d8c-9837-14de0604b3f7"
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.2.2)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_unh-1lEOwG"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gy_2xRXv-Ay"
      },
      "source": [
        "%matplotlib inline\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "sns.set()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS5yNhKMIOxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5fc7401-efe5-438d-a21b-3da3292dc08b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\r\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, MinMaxScaler\r\n",
        "from sklearn.metrics import classification_report, plot_confusion_matrix, roc_auc_score, confusion_matrix\r\n",
        "import imblearn\r\n",
        "import category_encoders as ce\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKUvsqpYKrF3"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "from sklearn.ensemble import AdaBoostClassifier \r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.dummy import DummyClassifier\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3bXsceQ4qb5"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZOxRSl14tU6",
        "outputId": "7e623c73-093b-4e04-f61c-b83cc288239d"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "AzCo6qqz4u9S",
        "outputId": "8bcdfd28-991a-43f4-f6dd-c2f37841f941"
      },
      "source": [
        "# load data into df variable\r\n",
        "df = pd.read_csv('/content/gdrive/My Drive/Assignment 3/ex3_data.csv')\r\n",
        "df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>INTENSIVE</th>\n",
              "      <th>NEWSITEID</th>\n",
              "      <th>RISK10YRS</th>\n",
              "      <th>INCLUSIONFRS</th>\n",
              "      <th>SBP</th>\n",
              "      <th>DBP</th>\n",
              "      <th>N_AGENTS</th>\n",
              "      <th>NOAGENTS</th>\n",
              "      <th>SMOKE_3CAT</th>\n",
              "      <th>ASPIRIN</th>\n",
              "      <th>EGFR</th>\n",
              "      <th>SCREAT</th>\n",
              "      <th>SUB_CKD</th>\n",
              "      <th>RACE_BLACK</th>\n",
              "      <th>AGE</th>\n",
              "      <th>FEMALE</th>\n",
              "      <th>SUB_CVD</th>\n",
              "      <th>SUB_CLINICALCVD</th>\n",
              "      <th>SUB_SUBCLINICALCVD</th>\n",
              "      <th>SUB_SENIOR</th>\n",
              "      <th>RACE4</th>\n",
              "      <th>CHR</th>\n",
              "      <th>GLUR</th>\n",
              "      <th>HDL</th>\n",
              "      <th>TRR</th>\n",
              "      <th>UMALCR</th>\n",
              "      <th>BMI</th>\n",
              "      <th>STATIN</th>\n",
              "      <th>SBPTERTILE</th>\n",
              "      <th>EVENT_PRIMARY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Regular</td>\n",
              "      <td>74.0</td>\n",
              "      <td>29.732061</td>\n",
              "      <td>True</td>\n",
              "      <td>145</td>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>67.69</td>\n",
              "      <td>1.11</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>60</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>155</td>\n",
              "      <td>81</td>\n",
              "      <td>36</td>\n",
              "      <td>92</td>\n",
              "      <td>5.80</td>\n",
              "      <td>33.115201</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regular</td>\n",
              "      <td>8.0</td>\n",
              "      <td>29.677619</td>\n",
              "      <td>True</td>\n",
              "      <td>138</td>\n",
              "      <td>71</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>60.64</td>\n",
              "      <td>1.17</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>75</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>243</td>\n",
              "      <td>107</td>\n",
              "      <td>61</td>\n",
              "      <td>188</td>\n",
              "      <td>5.45</td>\n",
              "      <td>28.842380</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Intensive</td>\n",
              "      <td>25.0</td>\n",
              "      <td>17.443819</td>\n",
              "      <td>True</td>\n",
              "      <td>143</td>\n",
              "      <td>92</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>68.44</td>\n",
              "      <td>1.09</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>62</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>180</td>\n",
              "      <td>116</td>\n",
              "      <td>47</td>\n",
              "      <td>125</td>\n",
              "      <td>13.33</td>\n",
              "      <td>33.643060</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Regular</td>\n",
              "      <td>96.0</td>\n",
              "      <td>8.627849</td>\n",
              "      <td>False</td>\n",
              "      <td>123</td>\n",
              "      <td>68</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>71.94</td>\n",
              "      <td>0.78</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>75</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>234</td>\n",
              "      <td>93</td>\n",
              "      <td>89</td>\n",
              "      <td>109</td>\n",
              "      <td>6.12</td>\n",
              "      <td>29.337871</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Intensive</td>\n",
              "      <td>42.0</td>\n",
              "      <td>23.751437</td>\n",
              "      <td>True</td>\n",
              "      <td>126</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>50.19</td>\n",
              "      <td>1.36</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>81</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>126</td>\n",
              "      <td>108</td>\n",
              "      <td>39</td>\n",
              "      <td>84</td>\n",
              "      <td>28.78</td>\n",
              "      <td>36.660286</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8741</th>\n",
              "      <td>Regular</td>\n",
              "      <td>102.0</td>\n",
              "      <td>10.896486</td>\n",
              "      <td>False</td>\n",
              "      <td>138</td>\n",
              "      <td>59</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>79.57</td>\n",
              "      <td>0.71</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>78</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>199</td>\n",
              "      <td>90</td>\n",
              "      <td>85</td>\n",
              "      <td>74</td>\n",
              "      <td>12.73</td>\n",
              "      <td>27.186534</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8742</th>\n",
              "      <td>Regular</td>\n",
              "      <td>98.0</td>\n",
              "      <td>8.646088</td>\n",
              "      <td>False</td>\n",
              "      <td>119</td>\n",
              "      <td>73</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>22.60</td>\n",
              "      <td>2.08</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>85</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>145</td>\n",
              "      <td>83</td>\n",
              "      <td>52</td>\n",
              "      <td>95</td>\n",
              "      <td>440.38</td>\n",
              "      <td>42.191997</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8743</th>\n",
              "      <td>Regular</td>\n",
              "      <td>99.0</td>\n",
              "      <td>24.191491</td>\n",
              "      <td>True</td>\n",
              "      <td>137</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>74.74</td>\n",
              "      <td>1.00</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>66</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>167</td>\n",
              "      <td>80</td>\n",
              "      <td>46</td>\n",
              "      <td>75</td>\n",
              "      <td>26.92</td>\n",
              "      <td>19.462021</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8744</th>\n",
              "      <td>Intensive</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.354619</td>\n",
              "      <td>True</td>\n",
              "      <td>154</td>\n",
              "      <td>93</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>32.32</td>\n",
              "      <td>1.64</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>56</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>245</td>\n",
              "      <td>103</td>\n",
              "      <td>37</td>\n",
              "      <td>369</td>\n",
              "      <td>3.20</td>\n",
              "      <td>35.579436</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8745</th>\n",
              "      <td>Intensive</td>\n",
              "      <td>74.0</td>\n",
              "      <td>7.459888</td>\n",
              "      <td>False</td>\n",
              "      <td>146</td>\n",
              "      <td>81</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>92.08</td>\n",
              "      <td>0.64</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>68</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>123</td>\n",
              "      <td>87</td>\n",
              "      <td>52</td>\n",
              "      <td>71</td>\n",
              "      <td>9.17</td>\n",
              "      <td>30.783013</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8746 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      INTENSIVE  NEWSITEID  RISK10YRS  ...  STATIN  SBPTERTILE  EVENT_PRIMARY\n",
              "0       Regular       74.0  29.732061  ...    True           3          False\n",
              "1       Regular        8.0  29.677619  ...    True           2          False\n",
              "2     Intensive       25.0  17.443819  ...   False           2          False\n",
              "3       Regular       96.0   8.627849  ...   False           1          False\n",
              "4     Intensive       42.0  23.751437  ...   False           1          False\n",
              "...         ...        ...        ...  ...     ...         ...            ...\n",
              "8741    Regular      102.0  10.896486  ...    True           2          False\n",
              "8742    Regular       98.0   8.646088  ...    True           1          False\n",
              "8743    Regular       99.0  24.191491  ...    True           2          False\n",
              "8744  Intensive       15.0  20.354619  ...   False           3          False\n",
              "8745  Intensive       74.0   7.459888  ...    True           3          False\n",
              "\n",
              "[8746 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6YV4rvW3DRk"
      },
      "source": [
        "# Split to Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RelRYWGX3IOC"
      },
      "source": [
        "# splitting the data into 70% train set and 30% test set.\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop(\"EVENT_PRIMARY\", axis=1), df.EVENT_PRIMARY, test_size = 0.3, random_state=0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmCZc1SV5KUa"
      },
      "source": [
        "# Exploring Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "0KR9GShHuoc6",
        "outputId": "0a87c4d6-0178-4e41-fd49-b78beb16789a"
      },
      "source": [
        "# get info about the columns type\r\n",
        "display(X_train.info())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6122 entries, 6138 to 2732\n",
            "Data columns (total 29 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   INTENSIVE           6122 non-null   object \n",
            " 1   NEWSITEID           5796 non-null   float64\n",
            " 2   RISK10YRS           6122 non-null   float64\n",
            " 3   INCLUSIONFRS        6122 non-null   bool   \n",
            " 4   SBP                 6122 non-null   int64  \n",
            " 5   DBP                 6122 non-null   int64  \n",
            " 6   N_AGENTS            6122 non-null   int64  \n",
            " 7   NOAGENTS            6122 non-null   bool   \n",
            " 8   SMOKE_3CAT          6122 non-null   int64  \n",
            " 9   ASPIRIN             6122 non-null   bool   \n",
            " 10  EGFR                6122 non-null   float64\n",
            " 11  SCREAT              6122 non-null   float64\n",
            " 12  SUB_CKD             6122 non-null   bool   \n",
            " 13  RACE_BLACK          6122 non-null   bool   \n",
            " 14  AGE                 6122 non-null   int64  \n",
            " 15  FEMALE              6122 non-null   bool   \n",
            " 16  SUB_CVD             6122 non-null   bool   \n",
            " 17  SUB_CLINICALCVD     6122 non-null   bool   \n",
            " 18  SUB_SUBCLINICALCVD  6122 non-null   bool   \n",
            " 19  SUB_SENIOR          6122 non-null   bool   \n",
            " 20  RACE4               6122 non-null   object \n",
            " 21  CHR                 6122 non-null   int64  \n",
            " 22  GLUR                6122 non-null   int64  \n",
            " 23  HDL                 6122 non-null   int64  \n",
            " 24  TRR                 6122 non-null   int64  \n",
            " 25  UMALCR              6122 non-null   float64\n",
            " 26  BMI                 6122 non-null   float64\n",
            " 27  STATIN              6122 non-null   bool   \n",
            " 28  SBPTERTILE          6122 non-null   int64  \n",
            "dtypes: bool(11), float64(6), int64(10), object(2)\n",
            "memory usage: 974.5+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLeaUuWD5Mx5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "2853d02b-4488-4ab7-d484-268b9f4d3cad"
      },
      "source": [
        "# get info about mean, std, min, max, values\r\n",
        "display(X_train.describe())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NEWSITEID</th>\n",
              "      <th>RISK10YRS</th>\n",
              "      <th>SBP</th>\n",
              "      <th>DBP</th>\n",
              "      <th>N_AGENTS</th>\n",
              "      <th>SMOKE_3CAT</th>\n",
              "      <th>EGFR</th>\n",
              "      <th>SCREAT</th>\n",
              "      <th>AGE</th>\n",
              "      <th>CHR</th>\n",
              "      <th>GLUR</th>\n",
              "      <th>HDL</th>\n",
              "      <th>TRR</th>\n",
              "      <th>UMALCR</th>\n",
              "      <th>BMI</th>\n",
              "      <th>SBPTERTILE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5796.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>55.891649</td>\n",
              "      <td>20.263013</td>\n",
              "      <td>139.741261</td>\n",
              "      <td>78.133616</td>\n",
              "      <td>1.824567</td>\n",
              "      <td>1.694218</td>\n",
              "      <td>71.576599</td>\n",
              "      <td>1.078386</td>\n",
              "      <td>68.038876</td>\n",
              "      <td>189.800229</td>\n",
              "      <td>98.936785</td>\n",
              "      <td>52.745018</td>\n",
              "      <td>125.324894</td>\n",
              "      <td>42.124802</td>\n",
              "      <td>29.851622</td>\n",
              "      <td>2.010291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>29.803121</td>\n",
              "      <td>10.896961</td>\n",
              "      <td>15.649653</td>\n",
              "      <td>12.012795</td>\n",
              "      <td>1.034417</td>\n",
              "      <td>0.693232</td>\n",
              "      <td>20.605170</td>\n",
              "      <td>0.341920</td>\n",
              "      <td>9.431987</td>\n",
              "      <td>40.905354</td>\n",
              "      <td>13.419479</td>\n",
              "      <td>14.436544</td>\n",
              "      <td>80.482783</td>\n",
              "      <td>165.513993</td>\n",
              "      <td>5.785701</td>\n",
              "      <td>0.820855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.863811</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>14.660000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>1.650000</td>\n",
              "      <td>13.734281</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>32.000000</td>\n",
              "      <td>12.097237</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>57.822500</td>\n",
              "      <td>0.860000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>161.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>5.610000</td>\n",
              "      <td>25.883594</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>57.000000</td>\n",
              "      <td>17.985340</td>\n",
              "      <td>138.500000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>71.115000</td>\n",
              "      <td>1.010000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>186.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>106.500000</td>\n",
              "      <td>9.515000</td>\n",
              "      <td>29.052644</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>81.000000</td>\n",
              "      <td>25.768375</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>84.470000</td>\n",
              "      <td>1.220000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>214.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>21.740000</td>\n",
              "      <td>32.956593</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>102.000000</td>\n",
              "      <td>81.187680</td>\n",
              "      <td>231.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>186.190000</td>\n",
              "      <td>4.040000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>437.000000</td>\n",
              "      <td>286.000000</td>\n",
              "      <td>161.000000</td>\n",
              "      <td>1701.000000</td>\n",
              "      <td>4125.000000</td>\n",
              "      <td>63.932902</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         NEWSITEID    RISK10YRS  ...          BMI   SBPTERTILE\n",
              "count  5796.000000  6122.000000  ...  6122.000000  6122.000000\n",
              "mean     55.891649    20.263013  ...    29.851622     2.010291\n",
              "std      29.803121    10.896961  ...     5.785701     0.820855\n",
              "min       1.000000     1.863811  ...    13.734281     1.000000\n",
              "25%      32.000000    12.097237  ...    25.883594     1.000000\n",
              "50%      57.000000    17.985340  ...    29.052644     2.000000\n",
              "75%      81.000000    25.768375  ...    32.956593     3.000000\n",
              "max     102.000000    81.187680  ...    63.932902     3.000000\n",
              "\n",
              "[8 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuI6bkg86vHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18115f85-492c-43c1-acdd-d4a35cf01527"
      },
      "source": [
        "# show number of missing values\r\n",
        "num_missing = X_train.isnull().sum()\r\n",
        "num_missing"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "INTENSIVE               0\n",
              "NEWSITEID             326\n",
              "RISK10YRS               0\n",
              "INCLUSIONFRS            0\n",
              "SBP                     0\n",
              "DBP                     0\n",
              "N_AGENTS                0\n",
              "NOAGENTS                0\n",
              "SMOKE_3CAT              0\n",
              "ASPIRIN                 0\n",
              "EGFR                    0\n",
              "SCREAT                  0\n",
              "SUB_CKD                 0\n",
              "RACE_BLACK              0\n",
              "AGE                     0\n",
              "FEMALE                  0\n",
              "SUB_CVD                 0\n",
              "SUB_CLINICALCVD         0\n",
              "SUB_SUBCLINICALCVD      0\n",
              "SUB_SENIOR              0\n",
              "RACE4                   0\n",
              "CHR                     0\n",
              "GLUR                    0\n",
              "HDL                     0\n",
              "TRR                     0\n",
              "UMALCR                  0\n",
              "BMI                     0\n",
              "STATIN                  0\n",
              "SBPTERTILE              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y7CpdrrQeSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2aecbc8-a629-49cd-8981-2c4e3eaaa639"
      },
      "source": [
        "# Checking Imbalance classes\r\n",
        "true_cases = [x for x in df.EVENT_PRIMARY if x == True]\r\n",
        "print(true_cases[0] == 1)\r\n",
        "false_cases = [x for x in df.EVENT_PRIMARY if x == False]\r\n",
        "print(f\"Number of True cases: {len(true_cases)}\")\r\n",
        "print(f\"Number of False cases: {len(false_cases)}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Number of True cases: 539\n",
            "Number of False cases: 8207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXNxbcvhEVr_"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru3FmRMQGG6A"
      },
      "source": [
        "### Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMIX3xOsUpbf"
      },
      "source": [
        "# Fill missing values\r\n",
        "X_train = X_train.fillna(value = 0)\r\n",
        "X_test = X_test.fillna(value=0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ImjUK3Q-yLb"
      },
      "source": [
        "### Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH4TwsIDGI6O"
      },
      "source": [
        "# encodes intensive to 1 and 0\r\n",
        "def intensive_encode(value):\r\n",
        "  if value == \"Regular\":\r\n",
        "    return 0\r\n",
        "  return 1\r\n",
        "\r\n",
        "X_train[\"INTENSIVE\"] = X_train[\"INTENSIVE\"].apply(intensive_encode)\r\n",
        "X_test[\"INTENSIVE\"] = X_test[\"INTENSIVE\"].apply(intensive_encode)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vynn3QOgrxEx"
      },
      "source": [
        "# encode boolean to integers\r\n",
        "encode = OrdinalEncoder()\r\n",
        "columns = X_train.select_dtypes(\"boolean\").columns\r\n",
        "\r\n",
        "X_train[columns] = encode.fit_transform(X_train[columns])\r\n",
        "X_test[columns] = encode.transform(X_test[columns])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxzdi3TZEDZL",
        "outputId": "1fb6a7ff-6fa3-4859-c78e-4e6b31eb9892"
      },
      "source": [
        "# binary encoding\r\n",
        "def binary_enc(column):\r\n",
        "  encoder = ce.BinaryEncoder(cols=[column])\r\n",
        "  train = encoder.fit_transform(X_train)\r\n",
        "  test = encoder.transform(X_test)\r\n",
        "  return train, test\r\n",
        "  \r\n",
        "for column in [\"NEWSITEID\", \"RACE4\"]:\r\n",
        "  X_train, X_test = binary_enc(column)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n",
            "/usr/local/lib/python3.6/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0v5AGeZ2Duz"
      },
      "source": [
        "### Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU-CEhsh2Fdu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "72fea34e-094d-423c-f2b8-0f1b3fd6f647"
      },
      "source": [
        "# Scaling by removing the mean and scaling to unit variance \r\n",
        "\"\"\"\r\n",
        "#scaler = MinMaxScaler()\r\n",
        "scaler = StandardScaler()\r\n",
        "\r\n",
        "def scaling(train, test, scaler):\r\n",
        "  train_new = scaler.fit_transform(train)\r\n",
        "  test_new = scaler.transform(test)\r\n",
        "  return train_new, test_new\r\n",
        "\r\n",
        "\r\n",
        "columns = [\"RISK10YRS\",\t\"SBP\",\t\"DBP\", \"EGFR\",\t\"SCREAT\", \"CHR\",\t\"GLUR\"\t,\"HDL\",\t\"TRR\",\t\"UMALCR\",\t\"BMI\", \"AGE\"]\r\n",
        "for column in columns:\r\n",
        "  X_train[column], X_test[column] = scaling(X_train[[column]], X_test[[column]], scaler)\r\n",
        "\"\"\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#scaler = MinMaxScaler()\\nscaler = StandardScaler()\\n\\ndef scaling(train, test, scaler):\\n  train_new = scaler.fit_transform(train)\\n  test_new = scaler.transform(test)\\n  return train_new, test_new\\n\\n\\ncolumns = [\"RISK10YRS\",\\t\"SBP\",\\t\"DBP\", \"EGFR\",\\t\"SCREAT\", \"CHR\",\\t\"GLUR\"\\t,\"HDL\",\\t\"TRR\",\\t\"UMALCR\",\\t\"BMI\", \"AGE\"]\\nfor column in columns:\\n  X_train[column], X_test[column] = scaling(X_train[[column]], X_test[[column]], scaler)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mucufaTRKOiI"
      },
      "source": [
        "### Explore data after transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "ibLHAA0B4wl7",
        "outputId": "7e8e17f4-72c5-47d6-ecd2-20604e4b6ca3"
      },
      "source": [
        "# show X_train after pre processing\r\n",
        "display(X_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>INTENSIVE</th>\n",
              "      <th>NEWSITEID_0</th>\n",
              "      <th>NEWSITEID_1</th>\n",
              "      <th>NEWSITEID_2</th>\n",
              "      <th>NEWSITEID_3</th>\n",
              "      <th>NEWSITEID_4</th>\n",
              "      <th>NEWSITEID_5</th>\n",
              "      <th>NEWSITEID_6</th>\n",
              "      <th>NEWSITEID_7</th>\n",
              "      <th>RISK10YRS</th>\n",
              "      <th>INCLUSIONFRS</th>\n",
              "      <th>SBP</th>\n",
              "      <th>DBP</th>\n",
              "      <th>N_AGENTS</th>\n",
              "      <th>NOAGENTS</th>\n",
              "      <th>SMOKE_3CAT</th>\n",
              "      <th>ASPIRIN</th>\n",
              "      <th>EGFR</th>\n",
              "      <th>SCREAT</th>\n",
              "      <th>SUB_CKD</th>\n",
              "      <th>RACE_BLACK</th>\n",
              "      <th>AGE</th>\n",
              "      <th>FEMALE</th>\n",
              "      <th>SUB_CVD</th>\n",
              "      <th>SUB_CLINICALCVD</th>\n",
              "      <th>SUB_SUBCLINICALCVD</th>\n",
              "      <th>SUB_SENIOR</th>\n",
              "      <th>RACE4_0</th>\n",
              "      <th>RACE4_1</th>\n",
              "      <th>RACE4_2</th>\n",
              "      <th>CHR</th>\n",
              "      <th>GLUR</th>\n",
              "      <th>HDL</th>\n",
              "      <th>TRR</th>\n",
              "      <th>UMALCR</th>\n",
              "      <th>BMI</th>\n",
              "      <th>STATIN</th>\n",
              "      <th>SBPTERTILE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6138</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>28.319732</td>\n",
              "      <td>1.0</td>\n",
              "      <td>117</td>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>89.63</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>82</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>194</td>\n",
              "      <td>92</td>\n",
              "      <td>47</td>\n",
              "      <td>77</td>\n",
              "      <td>4.83</td>\n",
              "      <td>27.580476</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3447</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11.690513</td>\n",
              "      <td>0.0</td>\n",
              "      <td>118</td>\n",
              "      <td>57</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>62.59</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>124</td>\n",
              "      <td>90</td>\n",
              "      <td>50</td>\n",
              "      <td>74</td>\n",
              "      <td>13.01</td>\n",
              "      <td>25.696259</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6459</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>43.604612</td>\n",
              "      <td>1.0</td>\n",
              "      <td>158</td>\n",
              "      <td>66</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>39.21</td>\n",
              "      <td>1.67</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>164</td>\n",
              "      <td>103</td>\n",
              "      <td>45</td>\n",
              "      <td>87</td>\n",
              "      <td>356.94</td>\n",
              "      <td>38.843269</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22.657058</td>\n",
              "      <td>1.0</td>\n",
              "      <td>136</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.56</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>194</td>\n",
              "      <td>102</td>\n",
              "      <td>43</td>\n",
              "      <td>128</td>\n",
              "      <td>3.01</td>\n",
              "      <td>26.572146</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5328</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>17.742077</td>\n",
              "      <td>1.0</td>\n",
              "      <td>140</td>\n",
              "      <td>88</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>94.35</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>188</td>\n",
              "      <td>93</td>\n",
              "      <td>66</td>\n",
              "      <td>74</td>\n",
              "      <td>8.33</td>\n",
              "      <td>27.396015</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4373</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>15.087441</td>\n",
              "      <td>1.0</td>\n",
              "      <td>143</td>\n",
              "      <td>71</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.78</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>229</td>\n",
              "      <td>108</td>\n",
              "      <td>46</td>\n",
              "      <td>206</td>\n",
              "      <td>14.02</td>\n",
              "      <td>29.264266</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7891</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19.103985</td>\n",
              "      <td>1.0</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>76.22</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>188</td>\n",
              "      <td>95</td>\n",
              "      <td>66</td>\n",
              "      <td>52</td>\n",
              "      <td>6.00</td>\n",
              "      <td>30.131742</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4859</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15.505326</td>\n",
              "      <td>1.0</td>\n",
              "      <td>133</td>\n",
              "      <td>83</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.26</td>\n",
              "      <td>2.20</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>207</td>\n",
              "      <td>93</td>\n",
              "      <td>61</td>\n",
              "      <td>145</td>\n",
              "      <td>23.08</td>\n",
              "      <td>29.308172</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3264</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>39.637833</td>\n",
              "      <td>1.0</td>\n",
              "      <td>156</td>\n",
              "      <td>72</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>71.68</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>111</td>\n",
              "      <td>93</td>\n",
              "      <td>54</td>\n",
              "      <td>91</td>\n",
              "      <td>23.44</td>\n",
              "      <td>26.858258</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2732</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>61.653135</td>\n",
              "      <td>1.0</td>\n",
              "      <td>183</td>\n",
              "      <td>67</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>34.18</td>\n",
              "      <td>1.87</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>200</td>\n",
              "      <td>93</td>\n",
              "      <td>50</td>\n",
              "      <td>174</td>\n",
              "      <td>18.67</td>\n",
              "      <td>25.017554</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6122 rows × 38 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      INTENSIVE  NEWSITEID_0  NEWSITEID_1  ...        BMI  STATIN  SBPTERTILE\n",
              "6138          1            0            0  ...  27.580476     0.0           1\n",
              "3447          0            0            0  ...  25.696259     1.0           1\n",
              "6459          0            0            0  ...  38.843269     0.0           3\n",
              "4798          0            0            0  ...  26.572146     0.0           2\n",
              "5328          1            0            0  ...  27.396015     1.0           2\n",
              "...         ...          ...          ...  ...        ...     ...         ...\n",
              "4373          1            0            1  ...  29.264266     0.0           2\n",
              "7891          0            0            0  ...  30.131742     1.0           1\n",
              "4859          0            0            0  ...  29.308172     1.0           2\n",
              "3264          1            0            1  ...  26.858258     1.0           3\n",
              "2732          0            0            0  ...  25.017554     1.0           3\n",
              "\n",
              "[6122 rows x 38 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "3mGTr6lGA9Vi",
        "outputId": "7673fe74-7391-4618-d35c-454f9e55a411"
      },
      "source": [
        "# X_Train after pre processing\r\n",
        "display(X_train.describe())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>INTENSIVE</th>\n",
              "      <th>NEWSITEID_0</th>\n",
              "      <th>NEWSITEID_1</th>\n",
              "      <th>NEWSITEID_2</th>\n",
              "      <th>NEWSITEID_3</th>\n",
              "      <th>NEWSITEID_4</th>\n",
              "      <th>NEWSITEID_5</th>\n",
              "      <th>NEWSITEID_6</th>\n",
              "      <th>NEWSITEID_7</th>\n",
              "      <th>RISK10YRS</th>\n",
              "      <th>INCLUSIONFRS</th>\n",
              "      <th>SBP</th>\n",
              "      <th>DBP</th>\n",
              "      <th>N_AGENTS</th>\n",
              "      <th>NOAGENTS</th>\n",
              "      <th>SMOKE_3CAT</th>\n",
              "      <th>ASPIRIN</th>\n",
              "      <th>EGFR</th>\n",
              "      <th>SCREAT</th>\n",
              "      <th>SUB_CKD</th>\n",
              "      <th>RACE_BLACK</th>\n",
              "      <th>AGE</th>\n",
              "      <th>FEMALE</th>\n",
              "      <th>SUB_CVD</th>\n",
              "      <th>SUB_CLINICALCVD</th>\n",
              "      <th>SUB_SUBCLINICALCVD</th>\n",
              "      <th>SUB_SENIOR</th>\n",
              "      <th>RACE4_0</th>\n",
              "      <th>RACE4_1</th>\n",
              "      <th>RACE4_2</th>\n",
              "      <th>CHR</th>\n",
              "      <th>GLUR</th>\n",
              "      <th>HDL</th>\n",
              "      <th>TRR</th>\n",
              "      <th>UMALCR</th>\n",
              "      <th>BMI</th>\n",
              "      <th>STATIN</th>\n",
              "      <th>SBPTERTILE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.0</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "      <td>6122.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.505227</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.186540</td>\n",
              "      <td>0.307906</td>\n",
              "      <td>0.421431</td>\n",
              "      <td>0.481705</td>\n",
              "      <td>0.505554</td>\n",
              "      <td>0.517968</td>\n",
              "      <td>0.483339</td>\n",
              "      <td>20.263013</td>\n",
              "      <td>0.624796</td>\n",
              "      <td>139.741261</td>\n",
              "      <td>78.133616</td>\n",
              "      <td>1.824567</td>\n",
              "      <td>0.094414</td>\n",
              "      <td>1.694218</td>\n",
              "      <td>0.505554</td>\n",
              "      <td>71.576599</td>\n",
              "      <td>1.078386</td>\n",
              "      <td>0.290428</td>\n",
              "      <td>0.317380</td>\n",
              "      <td>68.038876</td>\n",
              "      <td>0.351356</td>\n",
              "      <td>0.204018</td>\n",
              "      <td>0.170206</td>\n",
              "      <td>0.053251</td>\n",
              "      <td>0.284548</td>\n",
              "      <td>0.019438</td>\n",
              "      <td>0.875694</td>\n",
              "      <td>0.406076</td>\n",
              "      <td>189.800229</td>\n",
              "      <td>98.936785</td>\n",
              "      <td>52.745018</td>\n",
              "      <td>125.324894</td>\n",
              "      <td>42.124802</td>\n",
              "      <td>29.851622</td>\n",
              "      <td>0.441522</td>\n",
              "      <td>2.010291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.500014</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.389574</td>\n",
              "      <td>0.461665</td>\n",
              "      <td>0.493829</td>\n",
              "      <td>0.499706</td>\n",
              "      <td>0.500010</td>\n",
              "      <td>0.499718</td>\n",
              "      <td>0.499763</td>\n",
              "      <td>10.896961</td>\n",
              "      <td>0.484215</td>\n",
              "      <td>15.649653</td>\n",
              "      <td>12.012795</td>\n",
              "      <td>1.034417</td>\n",
              "      <td>0.292427</td>\n",
              "      <td>0.693232</td>\n",
              "      <td>0.500010</td>\n",
              "      <td>20.605170</td>\n",
              "      <td>0.341920</td>\n",
              "      <td>0.453997</td>\n",
              "      <td>0.465495</td>\n",
              "      <td>9.431987</td>\n",
              "      <td>0.477433</td>\n",
              "      <td>0.403015</td>\n",
              "      <td>0.375844</td>\n",
              "      <td>0.224551</td>\n",
              "      <td>0.451236</td>\n",
              "      <td>0.138070</td>\n",
              "      <td>0.329957</td>\n",
              "      <td>0.491139</td>\n",
              "      <td>40.905354</td>\n",
              "      <td>13.419479</td>\n",
              "      <td>14.436544</td>\n",
              "      <td>80.482783</td>\n",
              "      <td>165.513993</td>\n",
              "      <td>5.785701</td>\n",
              "      <td>0.496609</td>\n",
              "      <td>0.820855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.863811</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.660000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>1.650000</td>\n",
              "      <td>13.734281</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.097237</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>57.822500</td>\n",
              "      <td>0.860000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>161.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>5.610000</td>\n",
              "      <td>25.883594</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>17.985340</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>138.500000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>71.115000</td>\n",
              "      <td>1.010000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>186.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>106.500000</td>\n",
              "      <td>9.515000</td>\n",
              "      <td>29.052644</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>25.768375</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>84.470000</td>\n",
              "      <td>1.220000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>214.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>21.740000</td>\n",
              "      <td>32.956593</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>81.187680</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>231.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>186.190000</td>\n",
              "      <td>4.040000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>437.000000</td>\n",
              "      <td>286.000000</td>\n",
              "      <td>161.000000</td>\n",
              "      <td>1701.000000</td>\n",
              "      <td>4125.000000</td>\n",
              "      <td>63.932902</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         INTENSIVE  NEWSITEID_0  ...       STATIN   SBPTERTILE\n",
              "count  6122.000000       6122.0  ...  6122.000000  6122.000000\n",
              "mean      0.505227          0.0  ...     0.441522     2.010291\n",
              "std       0.500014          0.0  ...     0.496609     0.820855\n",
              "min       0.000000          0.0  ...     0.000000     1.000000\n",
              "25%       0.000000          0.0  ...     0.000000     1.000000\n",
              "50%       1.000000          0.0  ...     0.000000     2.000000\n",
              "75%       1.000000          0.0  ...     1.000000     3.000000\n",
              "max       1.000000          0.0  ...     1.000000     3.000000\n",
              "\n",
              "[8 rows x 38 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GwivteCmCIH"
      },
      "source": [
        "# Imbalance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJOYZt3gB7gV"
      },
      "source": [
        "##### SMOTETomek - Used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5Rl4osGrtDU",
        "outputId": "54861f26-095e-4a4b-ade7-c34b5ca88ee5"
      },
      "source": [
        "from imblearn.combine import SMOTETomek\r\n",
        "\r\n",
        "smt = SMOTETomek(ratio='auto')\r\n",
        "X_smt, y_smt = smt.fit_sample(X_train, y_train)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaMSASFqBwep"
      },
      "source": [
        "##### TomekLinks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7b7zRoUmA_2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2416ae5f-e1d7-4176-f7df-49c7d505def4"
      },
      "source": [
        "\"\"\"\r\n",
        "from imblearn.under_sampling import TomekLinks\r\n",
        "\r\n",
        "tl = TomekLinks(return_indices=True, ratio='majority')\r\n",
        "X_tl, y_tl, id_tl = tl.fit_sample(X_train, y_train)\r\n",
        "\"\"\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfrom imblearn.under_sampling import TomekLinks\\n\\ntl = TomekLinks(return_indices=True, ratio='majority')\\nX_tl, y_tl, id_tl = tl.fit_sample(X_train, y_train)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIqkVNC8B2Dg"
      },
      "source": [
        "##### Cluser Centroids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "70SJv1qvpjok",
        "outputId": "0d412dd9-7964-42a9-e5f4-1af2413dec44"
      },
      "source": [
        "\"\"\"\r\n",
        "from imblearn.under_sampling import ClusterCentroids\r\n",
        "\r\n",
        "cc = ClusterCentroids(random_state=42)\r\n",
        "X_cc, y_cc = cc.fit_sample(X_train, y_train)\r\n",
        "\"\"\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom imblearn.under_sampling import ClusterCentroids\\n\\ncc = ClusterCentroids(random_state=42)\\nX_cc, y_cc = cc.fit_sample(X_train, y_train)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZJIW2aMB5lf"
      },
      "source": [
        "##### SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CmwezBjyq7cb",
        "outputId": "28f99feb-bdc6-43b8-d17f-59ea398e42dc"
      },
      "source": [
        "\"\"\"\r\n",
        "from imblearn.over_sampling import SMOTE\r\n",
        "\r\n",
        "smote = SMOTE(ratio='minority')\r\n",
        "X_sm, y_sm = smote.fit_sample(X_train, y_train)\r\n",
        "\"\"\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfrom imblearn.over_sampling import SMOTE\\n\\nsmote = SMOTE(ratio='minority')\\nX_sm, y_sm = smote.fit_sample(X_train, y_train)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRuond2iEfEN"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNsNzDTaE0hL"
      },
      "source": [
        "### Linear Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhkjozn5Ehih"
      },
      "source": [
        "logistic = LogisticRegression()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zai6MxZ4phqH"
      },
      "source": [
        "linear_params={'solver' : ['liblinear', 'saga', 'sag'],\\\r\n",
        "            'max_iter': np.arange(100,300,50),\r\n",
        "           'penalty': ['l2','l1', 'elasticnet', 'none'],\r\n",
        "            'n_jobs': [-1],\r\n",
        "            'random_state': [0],\r\n",
        "            'multi_class': ['ovr']}"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzPU9c7-E4Sf"
      },
      "source": [
        "### Ensemble Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV_iQLC8E6uF"
      },
      "source": [
        "adaboost = AdaBoostClassifier()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoWhbcHTq1RD"
      },
      "source": [
        "ensemble_params={'base_estimator' : [DecisionTreeClassifier(max_depth=1)],\\\r\n",
        "            'n_estimators': [100,200],\r\n",
        "           'learning_rate': [0.1,0.2,0.4,0.8,1],\r\n",
        "            'random_state': [0]}"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWOds5anE6-M"
      },
      "source": [
        "### Deep Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edn_I15hE9SN"
      },
      "source": [
        "def create_ann_model():\r\n",
        "  # Dense - Fully connected layers\r\n",
        "  ann_model = Sequential()\r\n",
        "  # First layer with 38 inputs and 32 nodes in first hidden layer\r\n",
        "  ann_model.add(Dense(32 ,activation='relu', input_dim=38))\r\n",
        "  # Second hidden layer with 16 nodes\r\n",
        "  ann_model.add(Dense(16, activation='relu'))\r\n",
        "  # Output a binary classifiers\r\n",
        "  ann_model.add(Dense(1, activation='sigmoid'))\r\n",
        "  ann_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['AUC'])\r\n",
        "  return ann_model\r\n",
        "\r\n",
        "ann_model = KerasClassifier(build_fn=create_ann_model)\r\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w8N-H6qq9bv"
      },
      "source": [
        "dl_params = {'epochs' : [20,30],\r\n",
        "              'batch_size' : [32,64],\r\n",
        "              }"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6sQ9UQ2Gwx7"
      },
      "source": [
        "### KFold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy6DVogeG059"
      },
      "source": [
        "k_fold = KFold(n_splits = 10, shuffle = True, random_state=0)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm74cMUcG3p3"
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrGSjpvxG4gX"
      },
      "source": [
        "# Grid search of combinations of feature extraction methods and machine learning methods with different parameters \r\n",
        "# in order to find the best combination \r\n",
        "def grid_search(model, model_name, parameters, X, y, score, kfold):\r\n",
        "    print(\"=\" * 80)\r\n",
        "    print(f\"Model: {model_name}\")\r\n",
        "    print(\"_\" * 80)\r\n",
        "    gs_clf = GridSearchCV(model, parameters, n_jobs=-1, cv=kfold, scoring=score, verbose=1)\r\n",
        "    gs_clf = gs_clf.fit(X,y)\r\n",
        "    print('Best score: ', gs_clf.best_score_)\r\n",
        "    print('Best params: ', gs_clf.best_params_)\r\n",
        "    return gs_clf.best_estimator_"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n61mK_25sK9Q",
        "outputId": "3da4d0f2-2e8b-42d3-caa8-1a9f7d5db620"
      },
      "source": [
        "# run grid search with the chosen model and its hyper-parameters\r\n",
        "models = [('DL', ann_model, None, 'accuracy'), ('linear',logistic, k_fold, 'roc_auc'), ('ensemble', adaboost, k_fold, 'roc_auc')]\r\n",
        "parameters = { 'DL': dl_params, 'linear' : linear_params, 'ensemble' : ensemble_params }\r\n",
        "best_models = {}\r\n",
        "\r\n",
        "for model_name, model, kfold, score in models:\r\n",
        "  best_model = grid_search(model, model_name,parameters[model_name], X_smt, y_smt, score, kfold)\r\n",
        "  best_models[model_name] =  best_model"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Model: DL\n",
            "________________________________________________________________________________\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  4.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 2.6766 - auc: 0.5152\n",
            "Epoch 2/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.7677 - auc: 0.6428\n",
            "Epoch 3/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.6641 - auc: 0.7025\n",
            "Epoch 4/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.6578 - auc: 0.7166\n",
            "Epoch 5/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.6146 - auc: 0.7419\n",
            "Epoch 6/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.6151 - auc: 0.7363\n",
            "Epoch 7/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.5980 - auc: 0.7590\n",
            "Epoch 8/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.5768 - auc: 0.7722\n",
            "Epoch 9/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.6036 - auc: 0.7561\n",
            "Epoch 10/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.5819 - auc: 0.7699\n",
            "Epoch 11/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.5873 - auc: 0.7634\n",
            "Epoch 12/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.5819 - auc: 0.7670\n",
            "Epoch 13/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.5796 - auc: 0.7702\n",
            "Epoch 14/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.5705 - auc: 0.7781\n",
            "Epoch 15/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.5696 - auc: 0.7791\n",
            "Epoch 16/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.5710 - auc: 0.7847\n",
            "Epoch 17/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.5732 - auc: 0.7778\n",
            "Epoch 18/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.5733 - auc: 0.7787\n",
            "Epoch 19/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.5655 - auc: 0.7836\n",
            "Epoch 20/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.5569 - auc: 0.7894\n",
            "Best score:  0.612403651394477\n",
            "Best params:  {'batch_size': 64, 'epochs': 20}\n",
            "================================================================================\n",
            "Model: linear\n",
            "________________________________________________________________________________\n",
            "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   54.6s\n",
            "[Parallel(n_jobs=-1)]: Done 329 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:  5.4min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score:  0.7453557000812006\n",
            "Best params:  {'max_iter': 100, 'multi_class': 'ovr', 'n_jobs': -1, 'penalty': 'l1', 'random_state': 0, 'solver': 'liblinear'}\n",
            "================================================================================\n",
            "Model: ensemble\n",
            "________________________________________________________________________________\n",
            "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  4.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score:  0.9806152912714359\n",
            "Best params:  {'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=1, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 200, 'random_state': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNJBByvgEh-B"
      },
      "source": [
        "# Testing + Comparing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M60Qgy5_Fd-"
      },
      "source": [
        "##### Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUJMbB2DEkyY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "c2ce676c-ff00-40cd-df0b-47c97df6f7f8"
      },
      "source": [
        "linear_model = best_models[\"linear\"]\r\n",
        "prediction = linear_model.predict(X_test)\r\n",
        "print(classification_report(y_test, prediction))\r\n",
        "plot_confusion_matrix(linear_model, X_test, y_test, normalize=None)\r\n",
        "print(f\"AUC Score: {roc_auc_score(y_test,prediction)}\")\r\n",
        "print(\"=====================\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.96      0.68      0.80      2467\n",
            "        True       0.10      0.59      0.18       157\n",
            "\n",
            "    accuracy                           0.67      2624\n",
            "   macro avg       0.53      0.63      0.49      2624\n",
            "weighted avg       0.91      0.67      0.76      2624\n",
            "\n",
            "AUC Score: 0.6332854830256197\n",
            "=====================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrtqDkmpKg_y"
      },
      "source": [
        "##### Ensemble Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "U3dxtAgZym5N",
        "outputId": "36b2021c-af8d-4ccd-d5a3-831b91512d83"
      },
      "source": [
        "ensemble = best_models[\"ensemble\"]\r\n",
        "prediction = ensemble.predict(X_test)\r\n",
        "print(classification_report(y_test, prediction))\r\n",
        "print(f\"AUC Score: {roc_auc_score(y_test,prediction)}\")\r\n",
        "plot_confusion_matrix(ensemble, X_test, y_test, normalize=None)\r\n",
        "print(\"=====================\")\r\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.94      1.00      0.97      2467\n",
            "        True       0.30      0.02      0.04       157\n",
            "\n",
            "    accuracy                           0.94      2624\n",
            "   macro avg       0.62      0.51      0.50      2624\n",
            "weighted avg       0.90      0.94      0.91      2624\n",
            "\n",
            "AUC Score: 0.5081354129283614\n",
            "=====================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q0r3IWdKnYN"
      },
      "source": [
        "##### DL model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dawBTWhlA2c8",
        "outputId": "935d1118-ad5e-4d44-9486-3f6da5d44af5"
      },
      "source": [
        "dl_model = best_models[\"DL\"]\r\n",
        "prediction = dl_model.predict(X_test)\r\n",
        "print(classification_report(y_test, prediction))\r\n",
        "print(f\"AUC Score: {roc_auc_score(y_test,prediction)}\")\r\n",
        "print(confusion_matrix(y_test,prediction , normalize=None))\r\n",
        "print(\"=====================\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.96      0.54      0.69      2467\n",
            "        True       0.08      0.66      0.15       157\n",
            "\n",
            "    accuracy                           0.55      2624\n",
            "   macro avg       0.52      0.60      0.42      2624\n",
            "weighted avg       0.91      0.55      0.66      2624\n",
            "\n",
            "AUC Score: 0.6032004626677234\n",
            "[[1342 1125]\n",
            " [  53  104]]\n",
            "=====================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F3Jnhu7VXXl"
      },
      "source": [
        "# Work Explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73nIhVE4WZ1r"
      },
      "source": [
        "First, we split the data to 70% train and 30% test. \r\n",
        "Then, we explored the train set, preprocessed the train and test set and realized:\r\n",
        "1. The dataset has missing values only in the \"NEWSITEID\" column and becuase it's a categorical column that says the site ID in which the participant was treated, we decided to replace the missing values with value of \"0\" (new value that it does not relate to any sample).  \r\n",
        "2. We encoded the columns that are non-numerical (i.e., boolean, categorical and ordinal) to numerical ones by: **binary encoder** for the RACE4 and NEWSITEID columns, for the INTENSIVE column we used 1 for 'Intensive' and 0 for 'Regular', and for the boolean columns we used **Ordinal encoder**.  \r\n",
        "3. We used **standard scaler** to scale the numerical columns (\"RISK10YRS\",\t\"SBP\",\t\"DBP\", \"EGFR\",\t\"SCREAT\", \"CHR\",\t\"GLUR\"\t,\"HDL\",\t\"TRR\",\t\"UMALCR\",\t\"BMI\", \"AGE\"). But the performance was degraded. And we also used **MinMaxScaler** - which improved the ensemble model but degraded the DL model.  \r\n",
        "4. We used imbalance techniques such as: SMOTE, TomekLinks, Cluster Centroids, and SMOTETomek, and we chose **SMOTETomek** that outperformed the other techniques. \r\n",
        "\r\n",
        "\\* The preprocess phase was learned on the train and applied on the train and test sets. \r\n",
        "\r\n",
        "Because the data are imbalanced and from a clinical trial we evaluated the models with **Auc_roc** and **Recall-Precision** metrics. These metrics were chosen because classifing TP is more important than classifying TN, and we prefer high FP than high FN because it's clinical data. \r\n",
        "\r\n",
        "**For each model we performed a grid search to find the best hyper-paramters.**\r\n",
        "\r\n",
        "For the linear model we checked logistic regression and linearSVM, and the logistic regression with Standard Scaler outperformed the linearSVM. The results on the test set were: AUC = 0.633, Recall = 0.61, Precision = 0.10\r\n",
        "\r\n",
        "For the ensemble model we checked Adaboost with DecisionTree classifier and RandomForest classifier. The Adaboost model with MinMaxScaler outperformed RandomForest. The results on the test set were: \r\n",
        "AUC = 0.533, Recall = 0.08, Precision = 0.25 \r\n",
        "\r\n",
        "For the DL model we used ANN with 2 hidden layers. The results were: AUC = 0.618, Recall = 0.68, Precision = 0.09"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGHV0Jaz340A"
      },
      "source": [
        "# Summary Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R2QniZE4AtK"
      },
      "source": [
        "We comapred between the three models' results and found out that the linear model AUC is greater than the others, but the Recall of the DL model is the greatest. If we prefer to balance between recall and precision we will choose the linear model, but if the recall is the only metric that is important we will choose the DL model. "
      ]
    }
  ]
}
